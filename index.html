<!doctype html>
<html lang=en>

<head>
	<meta charset=utf-8>
	<title>Sergi Chalauri</title>
	<link
		href="https://fonts.googleapis.com/css2?family=Crimson+Text:ital,wght@0,400;0,600;1,400&family=Fira+Mono:wght@400;500&display=swap"
		rel="stylesheet">
	<link href="style.css" rel="stylesheet" />
</head>

<body>
	<h1>Application dependency management in Python</h1>
	<pre>.DELETE_ON_ERROR:
SHELL := /bin/bash

WITH_VENV := source venv/bin/activate && 

.PHONY: clean
clean:
	rm -f .make.*
	rm -rf venv*

# Environment:

venv/bin/activate:
	/usr/bin/python3.8 --version
	virtualenv --python=/usr/bin/python3.8 venv

.make.venv: venv/bin/activate
	touch .make.venv

.make.venv.pip-tools: .make.venv requirements/pip-tools.txt
	${WITH_VENV} pip install -r requirements/pip-tools.txt
	touch .make.venv.pip-tools

.make.venv.dev: .make.venv.pip-tools
.make.venv.dev: requirements/pip-tools.txt requirements/base.txt requirements/dev.txt
	@ echo 'NOTE: `touch requirements/{base,deploy,dev}.txt` to snooze dependency upgrade when `.in` files are modified.'
	${WITH_VENV} pip-sync requirements/pip-tools.txt requirements/base.txt requirements/dev.txt
	touch .make.venv.dev

# Requirements:

requirements/base.txt: requirements/pip-tools.txt 
requirements/base.txt: requirements/base.in
requirements/base.txt: | .make.venv.pip-tools
	${WITH_VENV} pip-compile requirements/base.in

requirements/deploy.txt: requirements/pip-tools.txt requirements/base.txt 
requirements/deploy.txt: requirements/deploy.in
requirements/deploy.txt: | .make.venv.pip-tools
	${WITH_VENV} pip-compile requirements/deploy.in

requirements/dev.txt: requirements/pip-tools.txt requirements/base.txt requirements/deploy.txt 
requirements/dev.txt: requirements/dev.in
requirements/dev.txt: | .make.venv.pip-tools
	${WITH_VENV} pip-compile requirements/dev.in
	
.PHONY: requirements
requirements: requirements/base.txt requirements/dev.txt requirements/deploy.txt
	@ echo 'NOTE: `rm requirements/{base,deploy,dev}.txt` before `make requirements` to upgrade all the dependencies.'

# Entrypoints:

.PHONY: test-unit
test-unit: .make.venv.dev
	@ ${WITH_VENV} python -c 'import pytest; print("pytest would run as version " + pytest.__version__ + "!")'</pre>

	<p><code>Makefile</code> above automates <code>pip-tools</code> dependency management.<br>
		Say we just cloned a repo set up this way. We can run unit tests straight away* by <code>make test-unit</code>.
		It will:
	<ol>
		<li>create a new virtual environment under <code>venv</code>.</li>
		<li>Install <code>pip-tools</code> in it.</li>
		<li><code>pip-compile</code> all the <code>.in</code> requirements (application and development) in correct
			order to <code>.txt</code>.</li>
		<li><code>pip-sync</code> all the requirements.</li>
		<li>Run whatever we needed to run in the beginning, in this case - <code>pytest</code>.</li>
	</ol>
	Of course all of this happens under <code>venv</code> environment.<br>
	And of course the subsequent calls to <code>make test-unit</code> will simply invoke <code>pytest</code> since
	everything is already set up and up to date.<br>
	Pretty smart - everything is automatic.<br>
	<em>* Well, not quite that easy actually: we'd have to install <code>virtualenv</code> dependency and correct version
	of Python, here - 3.8.</em>
	</p>

	<p>
		Now, let's say we're testing out some new library, say <code>google-cloud-speech</code>.<br>
		All we have to do is <code>echo 'google-cloud-speech~=1.3.2' >> requirements/base.in</code> and
		then simply call <code>make test-unit</code> again:<br>
	<ol>
		<li>change in <code>base.in</code> will be detected and it will be compiled to <code>base.txt</code>.</li>
		<li>Since development requirements depend on <code>base.txt</code>, <code>dev.in</code> will get recompiled too
			to respect new application requirements.</li>
		<li>Virtual environment will be <code>pip-sync</code>-ed to new requirements.</li>
		<li>Unit tests will run and <code>from google.cloud import speech_v1</code> will work.</li>
	</ol>
	During all of this we're free to work on code and forget about manually managing dependencies - our virtual
	environment and pinned requirements are always up to date.
	</p>

	<p>
		<code>GNU Make</code> works with <code>pip-tools</code> especially well, since it's primarily designed for
		"compilation artifact" kind of tasks.<br>
		Application requirements <code>base.in</code> compile to corresponding <code>.txt</code> file, upon which
		development requirements depend - <code>dev.in</code> must respect what's inside already compiled
		<code>base.txt</code> and it is
		very easy to express such relationship with <code>GNU Make</code>. All we have to do is configure prerequisites
		correctly, as seen on <code>Makefile</code> above.<br>
		The "uncompiled" requirement files might look like this (Tucked inside
		<code>requirements</code> directory not to flood project root too much.):<br>
	<pre># requirements/base.in

-c pip-tools.txt

Flask~=1.1
loginpass~=0.3
numpy~=1.1
tensorflow~=2.0
google-cloud-storage~=1.2
google-cloud-ndb~=1.1

# requirements/deploy.in

-c pip-tools.txt
-c base.txt

gunicorn~=19.8

# requirements/dev.in

-c pip-tools.txt
-c base.txt
-c deploy.txt

pytest~=5.4
coverage~=5.0
freezegun~=0.3.13
ipython~=7.1
pandas~=0.23</pre>
	Note that <code>-c</code> constraints are followed by <code>Makefile</code> prerequisites.<br>
	Also note that <code>pip-tools.txt</code> doesn't "participate" in requirements compilation/installation flow to
	avoid chicken and egg problem - we couldn't <code>pip-compile pip-tools.in</code> without having
	<code>pip-tools</code> already installed.<br>
	You can think of Python + <code>pip-tools</code> as a "base" environment, upon which we can build workflow automation.
	</p>
</body>

</html>